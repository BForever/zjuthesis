
\chapter{备注}
\section{节标题}

我们可以用includegraphics来插入现有的jpg等格式的图片，
如\autoref{fig:zju-logo}所示。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=.3\linewidth]{logo/zju}
    \caption{\label{fig:zju-logo}浙江大学LOGO}
\end{figure}


\subsection{小节标题}


\par 如\autoref{tab:sample}所示，这是一张自动调节列宽的表格。

\begin{table}[htbp]
    \caption{\label{tab:sample}自动调节列宽的表格}
    \begin{tabularx}{\linewidth}{c|X<{\centering}}
        \hline
        第一列 & 第二列 \\ \hline
        xxx & xxx \\ \hline
        xxx & xxx \\ \hline
        xxx & xxx \\ \hline
    \end{tabularx}
\end{table}


\par 如\autoref{equ:sample}，这是一个公式

\begin{equation}
    \label{equ:sample}
    A=\overbrace{(a+b+c)+\underbrace{i(d+e+f)}_{\text{虚数}}}^{\text{复数}}
\end{equation}

\chapter{另一章}


\begin{figure}[htbp]
    \centering
    \includegraphics[width=.3\linewidth]{example-image-a}
    \caption{\label{fig:fig-placeholder}图片占位符}
\end{figure}

\chapter{引言}

近年来，物联网（IoT）产业发展迅速。根据[1]，2025年将安装820亿台物联网设备。因此，人们有越来越多的机会与这些设备进行交互。物联网设备可能具有人们可以操作的物理接口，例如按钮或开关。一种广泛接受的交互形式是使用应用程序通过另一个智能设备（如手机或笔记本电脑）控制设备[2]，[3]。此外，通过语音命令进行交互也变得越来越流行[4]，[5]。与上述人机交互形式相比，使用增强现实（AR）技术能够直接显示信息和界面。因此，人们认为它带来的互动打破了物理空间和网络空间之间的界限。

现有的研究试图通过类似AR的设计实现人机交互[6]，[7]。Snap-To-It[6]允许用户通过拍摄设备照片并发送到服务器来选择设备。如果照片与任何设备匹配，服务器将返回设备的控制界面并在手机上显示。SnapLink[7]实现了类似的设备控制，而不是使用图像定位方法进行设备识别。然而，他们只能将一台设备识别为一张拍摄的照片，这在速度上是不够的。[8] 研究了边缘辅助的实时移动增强现实技术，实现了高速移动。对于人机交互，[8]缺乏识别设备的能力。[9] -[11]提出的边缘辅助同步定位和映射（SLAM），实现了真正的实时SLAM。这可以用于实现基于AR的人机交互，但集成并非微不足道。
我们认为实现基于AR的人机交互有三个要求：1）视频帧中的设备应被准确识别和定位；2） 处理速度快，用户感觉不到延迟或冻结；3） 交互以用户为导向，以提高体验质量。此外，我们注意到一个有趣的现象，即人们不仅与可连接的设备（即具有基本通信能力的设备）交互，而且与不可连接的对象交互。例如，用户希望保留饲养植物的记录。因此，我们希望将可连接/不可连接的对象都视为交互目标，并且人-设备交互成为人-对象交互。

为了满足上述需求，我们提出了VSLink，它实现了快速对象识别和定制交互的边缘服务。我们设计了一种两步目标识别方法，以保证识别速度和准确性。两步目标识别技术利用视觉SLAM（VSLAM）和目标检测神经网络的互补特性，分别识别稳定/可移动的目标。VSLAM使用视觉特征点描述符来识别存储在地图中的稳定对象。在VSLAM过程之后，它生成一个检测先验，表示存在对象的区域。通过稀疏卷积[12]，神经网络的许多计算可以在这样的先验条件下跳过，从而导致显著的推理加速。我们还为用户提供了一个平台，以实现面向用户的交互。使用该平台，用户可以自定义交互目标、功能和界面，无需编码工作。
我们在包含20个对象的真实环境中评估了VSLink。结果表明，该系统支持30fps的视频输入，平均识别率为72.7\%。我们雇佣了10名志愿者通过VSLink实现他们的定制交互，他们确认VSLink的使用，设计过程的平均时间成本在两分钟内。

本文的贡献总结如下：
1.我们提出了VSLink，这是一种基于AR的人机交互方法，融合了物理空间和网络空间。我们提出了一种两步目标识别方法来快速准确地识别目标。我们设计了一个平台来实现面向用户的交互定制。
2.我们实现了VSLink，并在包含多个对象的环境中对其进行了评估。结果表明，在支持30FPS视频输入的情况下，具有很好的速度。
本文的其余部分组织如下。第2节介绍了VSLink的框架。在第3节和第4节中，我们描述了两步对象识别技术和定制交互设计。我们在第5节中介绍了VSLink的部署结果。在第6节中，我们介绍了相关的
作品我们在第8节中总结本文。

\chapter{系统架构}
图1显示了我们提出的VSLink的体系结构。在高层次上，交互涉及三个端，即移动设备端、边缘服务端和对象端。我们可以将交互流程总结如下。首先，用户使用智能手机对周围环境进行视频监控，视频帧通过无线链路发送到边缘服务端。第二，边缘服务识别视频帧中的对象。相应的用户界面（UI）及其位置将发送到智能手机。第三，手机在对象的位置显示UI，用户通过操作UI输入交互命令。最后，该命令由对象/电话/边缘服务根据命令属性进行处理。
为了实现上述流程并实现用户体验的准确性、速度和质量的目标，在边缘服务端我们提出了两个模块，即两步对象识别和对象管理与交互。对象标识模块识别当前帧中的对象，并在低延迟内返回其ID和位置。该模块借鉴VSLAM和目标检测神经网络的功能，实现快速准确的目标识别。具体来说，我们提前构建了环境的对象级SLAM映射。每次启动VSLink时，边缘服务端都会执行一个VSLAM线程。在通过构建的地图定位VSLAM的过程中，我们可以使用视觉特征点描述符匹配来识别稳定的对象。此外，为了处理移动目标，采用了目标检测神经网络。将VSLAM识别结果作为先验，提出了一种基于稀疏卷积的方法，避免了冗余计算。一旦一个物体被神经网络检测到，我们就使用图像检索方法来识别它的ID。
对象管理与交互模块实现了实际的人机交互。如果用户命令是由对象执行的，它会将用户命令发送给对象。例如，命令是打开某个设备。为了转发命令，边缘服务端与这些可连接对象建立连接，并集成它们的API。对于不可连接的对象，VSLink还提供了实现交互的功能，这主要依赖于智能手机的功能。

\chapter{两步物体识别}
\section{动机}
在计算机视觉领域，识别图像/视频中感兴趣的目标已经得到了很好的研究。例如，图像分类[13]、目标检测[14]、图像检索[15]、[16]和图像定位[17]可以实现不同程度的目标识别。在表一中，我们列出了这些方法的特点，但它们都不符合第一节中提到的要求。因此，我们将“目标检测+图像检索”方法与VSLAM相结合，以实现我们的目标识别。我们之所以选择这两种方法，是因为它们在许多方面表现出互补性。我们可以把环境中的物体大致分为两类，稳定的和可移动的。稳定物体往往位于固定位置，例如电视和空调。可移动的通常从一个地方移动到另一个地方。”“对象检测+图像检索”方法（为了简化表示，我们在下面省略图像检索）能够识别所有对象，但由于神经网络计算，速度较慢，而VSLAM识别稳定对象且速度较快。
图2显示了所提出的两步目标识别方法的框架。这种设计接近于实际人脑的工作方式。例如，如果一个人进入卧室，她/他可以立即知道电视的位置，并对自己进行基本定位。然而，要识别手机，此人确实需要注意搜索。直觉是，我们可以利用VSLAM的空间感知快速识别稳定的对象，然后让神经网络处理可移动的对象。同时，神经网络不需要对整个图像进行分析，只需要对其余区域进行分析，大大减少了时间开销。
\section{基于VSLAM的目标识别}
SLAM被认为是实现更真实AR体验的关键技术之一，因为它提供了对环境的理解和跟踪。在VSLink中，我们建议建立一个终身对象级SLAM映射，这有利于SLAM跟踪和对象识别。
1） 工作流：在这里，我们解释了所提出的基于VSLAM的对象识别解决方案的理论。由于经典的VS-LAM[18]，[19]技术试图在机器人第一次进入环境时实现精确的映射和定位，我们想知道机器人第二次进入环境时是否能够识别它所看到的物体。
构建的SLAM地图[18]仅包括某些地图点和关键帧，地图重用过程如图3所示。定位过程首先使用单词包（BoW）[20]计算当前帧的表示，然后计算当前帧和关键帧之间的BoW相似性。然后，它选择具有高弓相似性的关键帧作为候选帧。最后，对于每个选定的关键帧，它使用RANSAC[21]算法计算当前帧中的特征点与该关键帧的贴图点之间的2D-3D投影。如果投影误差小于阈值，则定位完成。